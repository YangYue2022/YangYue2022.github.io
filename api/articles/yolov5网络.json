{"title":"yolov5网络","uid":"18745307628dd554480cf2320609e50d","slug":"yolov5网络","date":"2023-04-17T15:53:25.817Z","updated":"2023-04-18T12:15:44.601Z","comments":true,"path":"api/articles/yolov5网络.json","keywords":null,"cover":[],"content":"<p>说在前面：感谢这位大佬<a href=\"https://blog.csdn.net/weixin_44791964\">Bubbliiiing 的博客_CSDN 博客-神经网络学习小记录,睿智的目标检测,有趣的数据结构算法领域博主</a><br>以下是一些学习笔记</p>\n<h1 id=\"YOLOv5\"><a href=\"#YOLOv5\" class=\"headerlink\" title=\"YOLOv5\"></a>YOLOv5</h1><p>YOLOv5 针对不同大小（ n , s , m , l , x ）的网络整体架构都是一样的，只不过会在每个子模块中采用不同的深度和宽度，分别应对 yaml 文件中的 depth_multiple 和 width_multiple 参数 Yolov5s 网络是 Yolov5 系列中<strong>深度最小</strong>，特征图的<strong>宽度最小</strong>的网络。后面的 3 种都是在此基础上不断加深，不断加宽。</p>\n<h2 id=\"yolov5-的改进\"><a href=\"#yolov5-的改进\" class=\"headerlink\" title=\"yolov5 的改进\"></a>yolov5 的改进</h2><ol>\n<li>使用了 Focus 网络结构，具体操作是在一张图片中每隔一个像素拿到一个值，压缩宽高，扩张通道数，宽高信息就集中到了通道信息,输入通道扩充了四倍。但是 YOLOv5 在 v6.0 版本后相比之前版本有一个很小的改动，把网络的第一层（原来是 Focus 模块）换成了一个 6x6 大小的卷积层。<strong>两者在理论上其实等价的</strong>，但是对于现有的一些 GPU 设备（以及相应的优化算法）使用 6x6 大小的卷积层比使用 Focus 模块更加高效。</li>\n<li><strong>Mosaic 数据增强</strong>采用了 4 张图片，<strong>随机缩放、随机裁剪、随机排布</strong>的方式进行拼接，对于小目标的检测效果是不错的。<br><strong>丰富数据集</strong>：随机使用 4 张图片，随机缩放，再随机分布进行拼接，丰富了检测数据集，尤其是随机缩放增加了小目标。<br><strong>减少 GPU</strong>：可能会有人说，随机缩放，普通的数据增强也可以做，但作者考虑到很多人可能只有一个 GPU，因此 Mosaic 增强训练时，可以直接计算 4 张图片的数据，使得 Mini-batch 大小并不需要很大，一个 GPU 就可以达到比较好的效果。<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>Mini-batch：梯度下降需要对所有样本进行处理过后然后走一步，如果样本规模大会导致效率低，这种梯度下降叫 full batch。 为了提高效率，将样本分成等量子集， 这些子集就称为 minibatch。假如我们用 for 循环遍历 1000 个子集， 针对子集做一次梯度下降，然后更新参数 w 和 b 的值。接着到下一个子集继续梯度下降。 遍历完所有的 mini batch 之后相当于在梯度下降中做了 1000 次迭代，将遍历一次所有样本的行为叫做一个 epoch。在 Mini-batch 下的梯度下降中做的事情跟 full batch 一样，只不过我们训练的数据是一个个的子集。 这样在一个 epoch 中就能进行 1000 次的梯度下降（走的步数多），而在 full batch 中只有一次，这提高了算法的运行速度。</p></blockquote>\n</li>\n</ol>\n<h2 id=\"网络结构\"><a href=\"#网络结构\" class=\"headerlink\" title=\"网络结构\"></a>网络结构</h2><p><img src=\"/img/image-20230417232507685.png\" alt=\"image-20230417232507685\"><br>Backbone：YoloV5 的主干特征提取网络，根据它的结构以及之前 Yolo 主干的叫法，我一般叫它 CSPDarknet，输入的图片首先会在 CSPDarknet 里面进行特征提取，提取到的特征可以被称作特征层，是输入图片的特征集合。在主干部分，我们获取了三个特征层进行下一步网络的构建，这三个特征层我称它为有 效特征层。<br>FPN（特征金字塔网络）：YoloV5 的加强特征提取网络，在主干部分获得的三个有效特征层会在这一部分进行特征融合，特征融合的目的是结合不同尺度的特征信息。在 FPN 部分，已经获得的有效特征层被用于继续提取特征。在 YoloV5 里依然使用到了 PAN 的结构，我们不仅会对特征进行上采样实现特征融合，还会对特征 再次进行下采样实现特征融合。<br>Yolo Head：YoloV5 的分类器与回归器，通过 CSPDarknet 和 FPN，我们已经可以获得三个加强过的有效特征层。每一个特征层都有宽、高和通道数，此时我们可以将特征图看作一个又一个特征点的集合，每一个特征 点都有通道数个特征。Yolo Head 实际上所做的工作就是对特征点进行判断，判断特征点是否有物体与其对应。与以前版本的 Yolo 一样，YoloV5 所用的解耦头是一起的，也就是分类和回归在一个 1X1 卷积里实现。<br>因此，整个 YoloV5 网络所作的工作就是 特征提取-特征加强-预测特征点对应的物体情况。</p>\n<h3 id=\"Backbone\"><a href=\"#Backbone\" class=\"headerlink\" title=\"Backbone\"></a>Backbone</h3><p><strong>卷积+标准化+激活函数</strong><br>进行高和宽的压缩和通道数的扩张<br>使用了 SiLU 激活函数，SiLU 是 Sigmoid 和 ReLU 的改进版。SiLU 具备无上界有下界、平滑、非单调的特性。<br>SiLU 在深层模型上的效果优于 ReLU。可以看做是平滑的 ReLU 激活函数。</p>\n<h4 id=\"CSPlayer\"><a href=\"#CSPlayer\" class=\"headerlink\" title=\"CSPlayer\"></a>CSPlayer</h4><p><strong>残差</strong><br>残差块：使用了<strong>残差网络 Residual</strong>，残差卷积可以分为两个部分，主干部分是一次 1X1 的卷积和一次 3X3 的卷积；残差边部分不做任何处理，直接将主干的输入与输出结合。<br><img src=\"/img/image-20230417233837780.png\" alt=\"image-20230417233837780\"><br>残差网络的作用：</p>\n<ol>\n<li>堆叠网络后网络难以收敛，而且梯度爆炸（梯度消失）在一开始就阻碍网络的收敛，让网络难以训练，得到适当的参数。</li>\n<li>理论上来讲，增加网络的层数，网络可以进行更加复杂的特征提取，可以取得更好的结果。但是实验发现深度网络出现了退化问题，因为在适当的深度模型上添加更多的层会导致了更高的训练误差，从而使其下降。<br>残差网络解决了上述问题：<br><img src=\"/img/image-20230417234125351.png\" alt=\"image-20230417234125351\"><br>对于这整个堆叠结构，当输入 x 时，它学习到的特征记为 H（x），因此我们希望他学习到的残差为 F（x）&#x3D; H（x）- x；那么我们最初学习到的特征就是 H（x）&#x3D; F（x）+ x。<br>假如本来我们要优化的目标是 H（x）&#x3D;F（x）+ x，但通过这个结构就把优化的目标有 H（x）转化成 H（x）-x。这时候就不是把上面几层训练到一个等价映射，而是将其逼近于 0，这样训练的难度比训练一个等价映射 应该下降多了。<br>CSPnet：将原来的残差块的堆叠进行了一个拆分，拆成左右两部分：<strong>主干部分继续进行原来的残差块的堆叠；另一部分则像一个残差边一样，经过少量处理直接连接到最后（concat）</strong>。<em>因此可以认为</em>CSP 中存在一个大的残差边。<br><img src=\"/img/image-20230417234141271.png\" alt=\"image-20230417234141271\"></li>\n</ol>\n<p>最后利用卷积进行通道整合<br>最后一个 CSPlayer 没有残差边</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>作者在论文阐述了 CSP 结构的优点:</p>\n<p>更丰富的梯度组合，同时减少计算量</p>\n<p>（1）加强 CNN 的学习能力；（2）减少计算瓶颈，现在的网络大多计算代价昂贵，不利于工业的落地；（3）减少内存消耗。</p></blockquote>\n<h4 id=\"SPP\"><a href=\"#SPP\" class=\"headerlink\" title=\"SPP\"></a>SPP</h4><p>通过不同池化核大小的最大池化进行特征提取，提高网络的感受野。在 YoloV4 中，SPP 是用在 FPN 里面的，<br>在 YoloV5 中，SPP 模块被用在了主干特征提取网络中。<br>实现局部特征和全局特征的融合<br><img src=\"/img/image-20230417234558689.png\" alt=\"image-20230417234558689\"></p>\n<h3 id=\"Neck\"><a href=\"#Neck\" class=\"headerlink\" title=\"Neck\"></a>Neck</h3><p><img src=\"/img/image-20230417234638722.png\" alt=\"image-20230417234638722\"></p>\n<p>FPN 是自顶向下，将高层的强语义特征传递下来，对整个金字塔进行增强，不过只增强了语义信息，对定位信息没有传递。PAN 就是针对这一点，在 FPN 的后面添加一个自底向上的金字塔，对 FPN 补充，将低层的强定位特征传递上去，又被称之为“双塔战术”。</p>\n<p>Concat 是通道数的增加（堆叠）；add 是特征图相加，通道数不变</p>\n<p><strong>yolohead</strong></p>\n<p>利用 FPN 特征金字塔，我们可以获得三个加强特征，这三个加强特征的 shape 分别为(20,20,1024(40,40,512)、(80,80,256)，然后我们利用这三个 shape 的特征层传入 Yolo Head 获得预测结果。</p>\n<p>对于每一个特征层，我们可以获得利用一个卷积调整通道数，最终的通道数和需要区分的种类个数相关，在 YoloV5 里，每一个特征层上每一个特征点存在 3 个先验框。</p>\n<p><img src=\"/img/image-20230417234717360.png\" alt=\"image-20230417234717360\"></p>\n<p>4+1：中心点的 x,y；预测框的宽高，是否有对应物体，属于哪一类别</p>\n<h2 id=\"预测\"><a href=\"#预测\" class=\"headerlink\" title=\"预测\"></a>预测</h2><p>得到最终的预测结果后还要进行得分排序与非极大抑制筛选。</p>\n<p><strong>得分筛选</strong>就是筛选出得分满足 confidence 置信度的预测框。</p>\n<p><strong>非极大抑制</strong>就是筛选出一定区域内属于同一种类得分最大的框。</p>\n<p>得分筛选与非极大抑制的过程可以概括如下：</p>\n<p>1、找出该图片中得分大于门限函数的框。在进行重合框筛选前就进行得分的筛选可以大幅度减少框的数 量。</p>\n<p>2、对种类进行循环，非极大抑制的作用是筛选出一定区域内属于同一种类得分最大的框，对种类进行循环</p>\n<p>可以帮助我们对每一个类分别进行非极大抑制。</p>\n<p>3、根据得分对该种类进行从大到小排序。</p>\n<p>4、每次取出得分最大的框，计算其与其它所有预测框的重合程度，重合程度过大的则剔除。</p>\n<p>得分筛选与非极大抑制后的结果就可以用于绘制预测框了。</p>\n<h2 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h2><p><strong>一维卷积核的降维和升维</strong></p>\n<p><img src=\"/img/image-20230417234901688.png\" alt=\"image-20230417234901688\"></p>\n","feature":true,"text":"说在前面：感谢这位大佬Bubbliiiing 的博客_CSDN 博客-神经网络学习小记录,睿智的目标检测,有趣的数据结构算法领域博主以下是一些学习笔记 YOLOv5YOLOv5 针对不同大小（ n , s , m , l , x ）的网络整体架构都是一样的，只不过会在每个子模块中...","link":"","photos":[],"count_time":{"symbolsCount":"3.4k","symbolsTime":"3 mins."},"categories":[],"tags":[{"name":"深度学习","slug":"深度学习","count":1,"path":"api/tags/深度学习.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#YOLOv5\"><span class=\"toc-text\">YOLOv5</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#yolov5-%E7%9A%84%E6%94%B9%E8%BF%9B\"><span class=\"toc-text\">yolov5 的改进</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84\"><span class=\"toc-text\">网络结构</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Backbone\"><span class=\"toc-text\">Backbone</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#CSPlayer\"><span class=\"toc-text\">CSPlayer</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#SPP\"><span class=\"toc-text\">SPP</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Neck\"><span class=\"toc-text\">Neck</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E9%A2%84%E6%B5%8B\"><span class=\"toc-text\">预测</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%85%B6%E4%BB%96\"><span class=\"toc-text\">其他</span></a></li></ol></li></ol>","author":{"name":"Serena","slug":"blog-author","avatar":"/img/logo.png","link":"/","description":"一位正在重塑知识的技术人 <br /> @ <b>QQ：1424935869</b>","socials":{"github":"https://github.com/YangYue2022","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://m.weibo.cn/","zhihu":"","csdn":"https://blog.csdn.net/Serena2000?spm=1000.2115.3001.5343","juejin":"","customs":{}}},"mapped":true,"prev_post":{},"next_post":{"title":"数据结构（1）","uid":"9b3e5c64d9c6600c826b6e407be811c5","slug":"数据结构1","date":"2023-03-12T16:00:00.000Z","updated":"2023-04-17T16:02:49.892Z","comments":true,"path":"api/articles/数据结构1.json","keywords":null,"cover":[],"text":"数据结构最近跟着 b 站上的王道课程重新学了一遍数据结构，以下是 c 语言版的实现,因为时间来不及有一些知识点没有敲代码带有主函数的代码可以看我的 github https://github.com/YangYue2022/DataStructure 线性表顺序表#顺序表的静态存...","link":"","photos":[],"count_time":{"symbolsCount":"31k","symbolsTime":"29 mins."},"categories":[],"tags":[{"name":"基础知识","slug":"基础知识","count":3,"path":"api/tags/基础知识.json"}],"author":{"name":"Serena","slug":"blog-author","avatar":"/img/logo.png","link":"/","description":"一位正在重塑知识的技术人 <br /> @ <b>QQ：1424935869</b>","socials":{"github":"https://github.com/YangYue2022","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://m.weibo.cn/","zhihu":"","csdn":"https://blog.csdn.net/Serena2000?spm=1000.2115.3001.5343","juejin":"","customs":{}}},"feature":true}}